{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linibm/Desktop/rag_example/rag_example/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/linibm/Desktop/rag_example/rag_example/lib/python3.10/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import faiss\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from rank_bm25 import BM25Okapi\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic zero-shot question generation and hybrid retrieval\n",
    "\n",
    "## Introduction\n",
    "This notebook demonstrates the use of a generative LLM to synthetically generate labeled question-passage pairs through zero-shot prompting.\n",
    "\n",
    "### Data\n",
    "The passages are extracted text chunks from 2 scientific papers regarding cheese:<br>\n",
    "Todaro et al. 2013: \"History, Processing and Quality Enhancement of Traditional Egyptian Kariesh Cheese: A Review\" (history_egyptian_cheese.json)<br>\n",
    "Marcellino, Benson 2013: \"The Good, the Bad, and the Ugly: Tales of Mold-Ripened Cheese\" (moldy_cheese.json)\n",
    "\n",
    "IBM Deepsearch Optical Character Recognition (OCR) was used to extract text chunks from PDF version of the scientific paper.<br> \n",
    "This showcases the utility of OCR to allow users to perform RAG on historical documents that have not been digitised and perhaps only fotographs / scans exist.\n",
    "\n",
    "IBM Deepsearch: https://research.ibm.com/projects/deep-search\n",
    "\n",
    "Due to using the demo version of IBM Deepsearch, only the top 20 Pages can be extracted. There is therefore a cutoff regarding moldy_cheese.json.\n",
    "\n",
    "## Objective\n",
    "The primary goal is to assess the retrieval system's accuracy by considering the passage from which each question was generated as the definitive true answer to the question.<br> This method allows for precise tuning of the interpolation parameter that balances the dense relevance scores and BM-25 relevance scores.\n",
    "\n",
    "## Methodological Background\n",
    "Based on the research from Ma et al. 2021, titled \"Zero-shot Neural Passage Retrieval via Domain-targeted Synthetic Question Generation,\" this method applies synthetic question generation to create a synthetic ground truth for the evaluation of retrieval systems on unlabled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Data Preprocessing, extract text from JSON file\n",
    "\"\"\"\n",
    "def extract_text_from_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    texts = []\n",
    "    main_text = data.get('main-text', [])\n",
    "    for item in main_text:\n",
    "        if 'text' in item:\n",
    "            texts.append(item['text'])\n",
    "    return texts\n",
    "\n",
    "filenames = ['data/moldy_cheese.json', 'data/history_egyptian_cheese.json']\n",
    "for filename in filenames:\n",
    "    extracted_texts = extract_text_from_file(filename)\n",
    "\n",
    "# Remove all Texts that are under length threshold\n",
    "filtered_texts = [text for text in extracted_texts if len(text) >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Split all texts in half that are causing trouble during embedding\n",
    "\"\"\"\n",
    "dense_retrieval = pipeline(\"feature-extraction\", model=\"BAAI/bge-small-en-v1.5\")\n",
    "updated_texts = []\n",
    "\n",
    "for text in filtered_texts:\n",
    "    try:\n",
    "        result = dense_retrieval(text, return_tensors=\"true\")\n",
    "        updated_texts.append(text)\n",
    "    \n",
    "    except Exception as e:\n",
    "        mid_point = len(text) // 2\n",
    "        part1 = text[:mid_point]\n",
    "        part2 = text[mid_point:]\n",
    "        \n",
    "        updated_texts.append(part1)\n",
    "        updated_texts.append(part2)\n",
    "\n",
    "filtered_texts = updated_texts\n",
    "print(\"Updated Texts:\", filtered_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Zero-shot synthetic question generation using OpenAI-API\n",
    "\"\"\"\n",
    "client = OpenAI(\n",
    "    api_key=\"\"\n",
    ")\n",
    "\n",
    "data = []\n",
    "\n",
    "# Iterate over filtered_texts with enumeration to create unique IDs\n",
    "for idx, text in enumerate(filtered_texts):\n",
    "\n",
    "    # Create unique IDs for question and passage\n",
    "    passage_id = f\"pa{idx+1}\"\n",
    "    question_id = f\"qu{idx+1}\"\n",
    "    \n",
    "    # Generate the question\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"Write a question based on the Passage. \n",
    "         The Question needs to be able to be answered by the given passage.\n",
    "         Do not start the question with \"based on the passage\".\n",
    "            Passage: {text}\"\"\"}\n",
    "    ])\n",
    "    result_question_text = completion.choices[0].message.content\n",
    "\n",
    "    data.append({\n",
    "        \"question_id\": question_id,\n",
    "        \"question_text\": result_question_text,\n",
    "        \"passage_id\": passage_id,\n",
    "        \"passage_text\": text\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.head(5))\n",
    "\n",
    "df.to_csv(\"data/generated_questions_passages.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Retrieval\n",
    "In order to gain the relevance scores from dense retrieval, the BAAI/bge-small-en-v1.5 Model is used create dense embeddings from the passages. <br>\n",
    "The Model creates one embedding vector for each word.\n",
    "\n",
    "Due to varying sequence length of the questions and passages, the embeddings need to be normalized in order to calculate the cosine-similarity between question and passages.<br>\n",
    "For normalization the embedding vector is averaged over the sequence length and projected to a single dimension.<br> \n",
    "This follows the mean pooling method suggested from hugging face:<br>\n",
    "https://www.youtube.com/watch?v=OATCgQtNX2o\n",
    "\n",
    "The Facebook AI Similarity Search (FAISS) library is then used to create an index over all normalized dense embedding vectors, which enables efficient similarity search of all the passages with a given question. \n",
    "\n",
    "FAISS documentation: https://faiss.ai/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Create dense embeddings and normalize by mean pooling\n",
    "\"\"\"\n",
    "df = pd.read_csv(\"data/generated_questions_passages.csv\")\n",
    "\n",
    "# Initialize HuggingFace embedding model pipeline\n",
    "embedder = pipeline(\"feature-extraction\", model=\"BAAI/bge-small-en-v1.5\", device=0) \n",
    "\n",
    "def get_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        emb = torch.tensor(embedder(text))  # Get embeddings\n",
    "        emb = torch.mean(emb, dim=1)  # Average across the sequence length\n",
    "        norm = torch.norm(emb, p=2, dim=1, keepdim=True)\n",
    "        emb = emb / norm  # Normalize\n",
    "        embeddings.append(emb.squeeze().numpy())\n",
    "    return np.array(embeddings)\n",
    "\n",
    "passages = filtered_texts\n",
    "passages = df['passage_text'].tolist()\n",
    "passage_embeddings = get_embeddings(passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Retrieve passage text, passage id and relevance scores for every generated question from FAISS index\n",
    "\"\"\"\n",
    "results = []\n",
    "\n",
    "# Initialize the FAISS index\n",
    "d = passage_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(passage_embeddings)\n",
    "\n",
    "# Conduct search for each generated question\n",
    "for i, row in df.iterrows():\n",
    "    query = [row['question_text']]\n",
    "    query_embedding = get_embeddings(query)\n",
    "    \n",
    "    # Search FAISS index\n",
    "    k = len(passages) \n",
    "    D, I = index.search(query_embedding, k)\n",
    "    \n",
    "    # Retrieve details based on indices from FAISS\n",
    "    retrieved_passages = [df['passage_text'][idx] for idx in I[0]]\n",
    "    retrieved_passage_ids = [df['passage_id'][idx] for idx in I[0]]\n",
    "    relevance_scores = D[0].tolist()\n",
    "\n",
    "    # Store the results\n",
    "    results.append({\n",
    "        \"query_id\": row['question_id'],\n",
    "        \"query_text\": row['question_text'],\n",
    "        \"retrieved_passage_ids\": \", \".join(retrieved_passage_ids),\n",
    "        \"retrieved_passages\": \" | \".join(retrieved_passages),\n",
    "        \"relevance_scores\": \", \".join(map(str, relevance_scores))\n",
    "    })\n",
    "\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "evaluation_df.to_csv(\"data/retrieval_evaluation_dense.csv\", index=False)\n",
    "\n",
    "print(evaluation_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Add BM-25 relevance scores for each passage regarding a question\n",
    "\"\"\"\n",
    "df = pd.read_csv(\"data/retrieval_evaluation_dense.csv\")\n",
    "\n",
    "# Split text by spaces to extract single words\n",
    "def tokenize(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "bm25_scores_list = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Extract passages from the row, seperator is ' | ' to account for commas in the text\n",
    "    passages = row['retrieved_passages'].split(' | ')\n",
    "\n",
    "    # Tokenize passages\n",
    "    tokenized_corpus = [tokenize(passage) for passage in passages]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    \n",
    "    # Tokenize questions\n",
    "    query = tokenize(row['query_text'])\n",
    "    \n",
    "    # Compute BM25 scores for the current query against all retrieved passages\n",
    "    bm25_scores = bm25.get_scores(query)\n",
    "    \n",
    "    # Add BM25 scores to list\n",
    "    bm25_scores_list.append(\", \".join(map(str, bm25_scores)))\n",
    "\n",
    "# Convert BM-25 scores list to new column in dataframe\n",
    "df['bm25_relevance_scores'] = bm25_scores_list\n",
    "df.to_csv(\"data/retrieval_evaluation_dense_bm25.csv\", index=False)\n",
    "\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Data processing step, merging ids and text of true passages from generated question-passage pairs\n",
    "\"\"\"\n",
    "\n",
    "retrieval_df = pd.read_csv(\"data/retrieval_evaluation_dense_bm25.csv\")\n",
    "questions_passages_df = pd.read_csv(\"data/generated_questions_passages.csv\")\n",
    "\n",
    "# Rename the columns in questions_passages_df to match retrieval_df\n",
    "questions_passages_df.rename(columns={'question_id': 'query_id'}, inplace=True)\n",
    "\n",
    "# Merge dataframes for true passages\n",
    "updated_df = pd.merge(retrieval_df, questions_passages_df[['query_id', 'passage_text', 'passage_id']],\n",
    "                      on='query_id', how='left')\n",
    "\n",
    "updated_df.rename(columns={\n",
    "    'passage_text': 'true_passage_text',\n",
    "    'passage_id': 'true_passage_id'\n",
    "}, inplace=True)\n",
    "\n",
    "updated_df.to_csv(\"data/retrieval_evaluation_dense_bm25.csv\", index=False)\n",
    "\n",
    "print(updated_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Data processing step, calculating the position of the true passage based on dense retrieval results\n",
    "\"\"\"\n",
    "updated_df = pd.read_csv(\"data/retrieval_evaluation_dense_bm25.csv\")\n",
    "\n",
    "def find_true_passage_position(row):\n",
    "    retrieved_ids = row['retrieved_passage_ids'].split(', ')\n",
    "    true_id = row['true_passage_id']\n",
    "    \n",
    "    try:\n",
    "        position = retrieved_ids.index(true_id) + 1\n",
    "    except ValueError:\n",
    "        position = -1\n",
    "    \n",
    "    return position\n",
    "\n",
    "updated_df['dense_true_passage_position'] = updated_df.apply(find_true_passage_position, axis=1)\n",
    "\n",
    "updated_df.to_csv(\"data/retrieval_evaluation_dense_bm25.csv\", index=False)\n",
    "\n",
    "\n",
    "print(updated_df.head(5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Search for optimal interpolation parameter between dense and BM-25 retrieval scores. Mean Reciprocal Rank (MRR) is used to measure retrieval performance.\n",
    "    Explaination for MRR: https://towardsdatascience.com/extended-reciprocal-rank-ranking-evaluation-metric-5929573c778a\n",
    "\"\"\" \n",
    "# Load DataFrame with dense and BM25 scores\n",
    "df = pd.read_csv(\"data/retrieval_evaluation_dense_bm25.csv\")\n",
    "\n",
    "# Function to calculate MRR\n",
    "def calculate_mrr(df, position_column):\n",
    "    df['reciprocal_rank'] = 1 / df[position_column]\n",
    "    return df['reciprocal_rank'].mean()\n",
    "\n",
    "best_lambda = None\n",
    "best_mrr = 0\n",
    "\n",
    "# Iterate over lambda values from 0 to 1 with 0.01 increments\n",
    "for lambda_param in [i / 100.0 for i in range(101)]:\n",
    "    new_true_positions = []\n",
    "    hybrid_scores_list = []\n",
    "\n",
    "    # Process each row to calculate hybrid scores and find new true passage position\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        # Parse and convert retrieval score strings to float lists\n",
    "        dense_scores = list(map(float, row['relevance_scores'].split(', ')))\n",
    "        bm25_scores = list(map(float, row['bm25_relevance_scores'].split(', ')))\n",
    "\n",
    "        # Calculate hybrid scores with current lambda\n",
    "        hybrid_scores = [dense + lambda_param * bm25 for dense, bm25 in zip(dense_scores, bm25_scores)]\n",
    "        hybrid_scores_list.append(\", \".join(map(str, hybrid_scores)))\n",
    "\n",
    "        # Get passage ids for sorting to find the new position of the true passage\n",
    "        retrieved_passage_ids = row['retrieved_passage_ids'].split(', ')\n",
    "        true_passage_id = row['true_passage_id']\n",
    "\n",
    "        # Calculate new position based on sorted hybrid scores\n",
    "        sorted_indices = sorted(range(len(hybrid_scores)), key=lambda k: hybrid_scores[k], reverse=True)\n",
    "        sorted_passage_ids = [retrieved_passage_ids[i] for i in sorted_indices]\n",
    "        true_position = sorted_passage_ids.index(true_passage_id) + 1  # 1-based index\n",
    "\n",
    "        new_true_positions.append(true_position)\n",
    "\n",
    "    df['hybrid_retrieval_scores'] = hybrid_scores_list\n",
    "    df['hybrid_true_passage_position'] = new_true_positions\n",
    "\n",
    "    current_mrr = calculate_mrr(df, 'hybrid_true_passage_position')\n",
    "    print(f\"Lambda: {lambda_param}, MRR: {current_mrr}\")\n",
    "\n",
    "    if current_mrr > best_mrr:\n",
    "        best_mrr = current_mrr\n",
    "        best_lambda = lambda_param\n",
    "\n",
    "# Print the best lambda and its MRR\n",
    "print(\"-------------------------------------------------\")\n",
    "print(f\"Best Lambda: {best_lambda}, Best MRR: {best_mrr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Performing one final run with the best lambda, code is reused from section above\n",
    "\"\"\"\n",
    "if best_lambda is not None:\n",
    "    final_true_positions = []\n",
    "    final_hybrid_scores_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        dense_scores = list(map(float, row['relevance_scores'].split(', ')))\n",
    "        bm25_scores = list(map(float, row['bm25_relevance_scores'].split(', ')))\n",
    "        final_hybrid_scores = [dense + best_lambda * bm25 for dense, bm25 in zip(dense_scores, bm25_scores)]\n",
    "        final_hybrid_scores_list.append(\", \".join(map(str, final_hybrid_scores)))\n",
    "\n",
    "        retrieved_passage_ids = row['retrieved_passage_ids'].split(', ')\n",
    "        true_passage_id = row['true_passage_id']\n",
    "\n",
    "        sorted_indices = sorted(range(len(final_hybrid_scores)), key=lambda k: final_hybrid_scores[k], reverse=True)\n",
    "        sorted_passage_ids = [retrieved_passage_ids[i] for i in sorted_indices]\n",
    "        final_true_position = sorted_passage_ids.index(true_passage_id) + 1\n",
    "\n",
    "        final_true_positions.append(final_true_position)\n",
    "\n",
    "    df['hybrid_retrieval_scores'] = final_hybrid_scores_list\n",
    "    df['hybrid_true_passage_position'] = final_true_positions\n",
    "\n",
    "df.drop('reciprocal_rank', axis=1, inplace=True)\n",
    "df.to_csv(\"data/retrieval_evaluation_hybrid_scores_tuned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Retrieval Method=Dense Retrieval<br>Top K=%{x}<br>Accuracy (%)=%{y}<extra></extra>",
         "legendgroup": "Dense Retrieval",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "Dense Retrieval",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20
         ],
         "xaxis": "x",
         "y": [
          80,
          81.66666666666667,
          83.33333333333334,
          86.66666666666667,
          93.33333333333333,
          93.33333333333333,
          93.33333333333333,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          96.66666666666667,
          98.33333333333333,
          98.33333333333333,
          98.33333333333333,
          98.33333333333333,
          100,
          100,
          100
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Retrieval Method=Hybrid Retrieval<br>Top K=%{x}<br>Accuracy (%)=%{y}<extra></extra>",
         "legendgroup": "Hybrid Retrieval",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "Hybrid Retrieval",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20
         ],
         "xaxis": "x",
         "y": [
          90,
          91.66666666666666,
          95,
          98.33333333333333,
          98.33333333333333,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100,
          100
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Retrieval Method"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Comparison of Top-K Accuracy: Dense vs. Hybrid Retrieval",
         "x": 0.5,
         "xanchor": "center"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "dtick": 1,
         "range": [
          0.5,
          20.5
         ],
         "tick0": 1,
         "tickmode": "linear",
         "title": {
          "text": "Top K"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Accuracy (%)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Visualizing advantage of hybrid retrieval using Top-K Accuracy\n",
    "    Top-K accuracy describes the accuracy of the retrieval method within the first K passages\n",
    "    --> Is the correct passage among the first K passages?\n",
    "\"\"\"\n",
    "df = pd.read_csv(\"data/retrieval_evaluation_hybrid_scores_tuned.csv\")\n",
    "\n",
    "max_k = 20  # Top-20 Accuracy\n",
    "\n",
    "def top_k_accuracy(df, column):\n",
    "    accuracies = []\n",
    "    for k in range(1, max_k + 1):\n",
    "        accuracy = (df[column] <= k).mean() * 100  # Percentage of passages within the top k\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies\n",
    "\n",
    "dense_accuracies = top_k_accuracy(df, 'dense_true_passage_position')\n",
    "hybrid_accuracies = top_k_accuracy(df, 'hybrid_true_passage_position')\n",
    "\n",
    "top_k_df = pd.DataFrame({\n",
    "    'Top K': range(1, max_k + 1),\n",
    "    'Dense Retrieval': dense_accuracies,\n",
    "    'Hybrid Retrieval': hybrid_accuracies\n",
    "})\n",
    "\n",
    "fig = px.line(top_k_df, x='Top K', y=top_k_df.columns[1:], markers=True,\n",
    "              labels={\"value\": \"Accuracy (%)\", \"variable\": \"Retrieval Method\"},\n",
    "              title=\"Comparison of Top-K Accuracy: Dense vs. Hybrid Retrieval\")\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickmode='linear', \n",
    "        tick0=1, \n",
    "        dtick=1, \n",
    "        range=[0.5, 20.5]  # Set the range from 1 to 20 with some padding\n",
    "    ),\n",
    "    yaxis=dict(title='Accuracy (%)'),\n",
    "    title=dict(x=0.5, xanchor='center'),\n",
    "    legend_title_text='Retrieval Method'\n",
    ")\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybrid_retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
